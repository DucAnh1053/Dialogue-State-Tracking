{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Import c√°c th∆∞ vi·ªán c·∫ßn thi·∫øt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from transformers import AutoTokenizer, DataCollatorWithPadding, DataCollatorForTokenClassification, AutoModelForSequenceClassification, AutoModelForTokenClassification, Trainer, TrainingArguments, pipeline\n",
    "import json\n",
    "import numpy as np\n",
    "import re\n",
    "import evaluate\n",
    "from collections import defaultdict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "val_list_path = 'MultiWOZ2.4-main/data/mwz24/MULTIWOZ2.4/valListFile.json'\n",
    "test_list_path = 'MultiWOZ2.4-main/data/mwz24/MULTIWOZ2.4/testListFile.json'\n",
    "data_path = 'MultiWOZ2.4-main/data/mwz24/MULTIWOZ2.4/data.json'\n",
    "dialogue_acts_path = 'MultiWOZ2.4-main/data/mwz24/MULTIWOZ2.4/dialogue_acts.json'\n",
    "ontology_path = 'MultiWOZ2.4-main/data/mwz24/MULTIWOZ2.4/ontology.json'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ƒê·ªçc danh s√°ch m√£ h·ªôi tho·∫°i val v√† test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(val_list_path) as f:\n",
    "    val_list = [line.strip() for line in f]\n",
    "    \n",
    "with open(test_list_path) as f:\n",
    "    test_list = [line.strip() for line in f]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ƒê·ªçc d·ªØ li·ªáu h·ªôi tho·∫°i"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(data_path) as f:\n",
    "    data = json.load(f)\n",
    "    \n",
    "with open(dialogue_acts_path) as f:\n",
    "    dialogue_acts = json.load(f)\n",
    "    \n",
    "with open(ontology_path) as f:\n",
    "    ontology = json.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "dialogue_ids = list(data.keys())\n",
    "\n",
    "train_list = [dialogue_id for dialogue_id in dialogue_ids if dialogue_id not in val_list and dialogue_id not in test_list]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# L·∫•y t·∫•t c·∫£ c√°c dialogue acts\n",
    "acts = set()\n",
    "\n",
    "for dialogue in dialogue_acts.values():\n",
    "    for turn in dialogue.values():\n",
    "        if turn == 'No Annotation':\n",
    "            continue\n",
    "        for act in turn.keys():\n",
    "            acts.add(act)\n",
    "            \n",
    "acts.add('No Annotation')\n",
    "acts = list(acts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "S·ªë l∆∞·ª£ng acts: 32\n",
      "['Restaurant-NoOffer', 'Taxi-Inform', 'No Annotation', 'Attraction-Recommend', 'Restaurant-Select', 'Train-Select', 'Train-Request', 'general-greet', 'Restaurant-Inform', 'general-reqmore', 'Booking-Inform', 'Hotel-Inform', 'general-bye', 'Hotel-Select', 'Booking-Request', 'Train-NoOffer', 'Attraction-Request', 'Booking-Book', 'Train-Inform', 'general-welcome', 'Taxi-Request', 'Booking-NoBook', 'Restaurant-Recommend', 'Hotel-Recommend', 'Attraction-Select', 'Attraction-Inform', 'Hotel-Request', 'Hotel-NoOffer', 'Attraction-NoOffer', 'Train-OfferBook', 'Restaurant-Request', 'Train-OfferBooked']\n"
     ]
    }
   ],
   "source": [
    "print('S·ªë l∆∞·ª£ng acts:', len(acts))\n",
    "print(acts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# T·∫°o m·ªôt t·ª´ ƒëi·ªÉn chuy·ªÉn ƒë·ªïi t·ª´ act sang index v√† ng∆∞·ª£c l·∫°i\n",
    "act2idx = {act: idx for idx, act in enumerate(acts)}\n",
    "idx2act = {idx: act for act, idx in act2idx.items()}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Danh s√°ch c√°c slot d·∫°ng ph√¢n lo·∫°i v√† kh√¥ng ph√¢n lo·∫°i\n",
    "# Danh s√°ch n√†y ƒë∆∞·ª£c ƒë·ªãnh nghƒ©a theo √Ω hi·ªÉu c√° nh√¢n\n",
    "# V·ªõi bi·∫øn ph√¢n lo·∫°i, ta s·∫Ω chuy·ªÉn th√†nh one-hot vector\n",
    "# V·ªõi bi·∫øn kh√¥ng ph√¢n lo·∫°i, ta s·∫Ω x√°c ƒë·ªãnh span c·ªßa n√≥ trong c√¢u\n",
    "\n",
    "categorical_slots = {\n",
    "    'attraction-area',\n",
    "    'attraction-type',\n",
    "    'bus-day',\n",
    "    'hotel-area',\n",
    "    'hotel-internet',\n",
    "    'hotel-parking',\n",
    "    'hotel-pricerange',\n",
    "    'hotel-stars',\n",
    "    'hotel-type',\n",
    "    'restaurant-area',\n",
    "    'restaurant-pricerange',\n",
    "    'train-departure',\n",
    "    'train-destination',\n",
    "}\n",
    "\n",
    "non_categorical_slots = {\n",
    "    'attraction-name',\n",
    "    'bus-arriveBy',\n",
    "    'bus-book people',\n",
    "    'bus-departure',\n",
    "    'bus-destination',\n",
    "    'bus-leaveAt',\n",
    "    'hospital-department',\n",
    "    'hotel-book day',\n",
    "    'hotel-book people',\n",
    "    'hotel-book stay',\n",
    "    'hotel-name',\n",
    "    'restaurant-book day',\n",
    "    'restaurant-book people',\n",
    "    'restaurant-book time',\n",
    "    'restaurant-food',\n",
    "    'restaurant-name',\n",
    "    'taxi-arriveBy',\n",
    "    'taxi-departure',\n",
    "    'taxi-destination',\n",
    "    'taxi-leaveAt',\n",
    "    'train-arriveBy',\n",
    "    'train-book people',\n",
    "    'train-day',\n",
    "    'train-leaveAt'\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "S·ªë l∆∞·ª£ng nh√£n BIO: 49\n",
      "['O', 'B-taxi-leaveAt', 'I-taxi-leaveAt', 'B-restaurant-book time', 'I-restaurant-book time', 'B-attraction-name', 'I-attraction-name', 'B-bus-arriveBy', 'I-bus-arriveBy', 'B-taxi-departure', 'I-taxi-departure', 'B-bus-departure', 'I-bus-departure', 'B-bus-leaveAt', 'I-bus-leaveAt', 'B-hotel-name', 'I-hotel-name', 'B-taxi-destination', 'I-taxi-destination', 'B-taxi-arriveBy', 'I-taxi-arriveBy', 'B-restaurant-name', 'I-restaurant-name', 'B-bus-book people', 'I-bus-book people', 'B-restaurant-food', 'I-restaurant-food', 'B-train-book people', 'I-train-book people', 'B-hospital-department', 'I-hospital-department', 'B-restaurant-book day', 'I-restaurant-book day', 'B-hotel-book day', 'I-hotel-book day', 'B-train-day', 'I-train-day', 'B-train-leaveAt', 'I-train-leaveAt', 'B-train-arriveBy', 'I-train-arriveBy', 'B-hotel-book people', 'I-hotel-book people', 'B-restaurant-book people', 'I-restaurant-book people', 'B-hotel-book stay', 'I-hotel-book stay', 'B-bus-destination', 'I-bus-destination']\n"
     ]
    }
   ],
   "source": [
    "# T·∫°o nh√£n BIO cho c√°c slot kh√¥ng ph√¢n lo·∫°i\n",
    "bio_list = ['O']\n",
    "bio_list.extend([item for slot in non_categorical_slots for item in [f'B-{slot}', f'I-{slot}']])\n",
    "print('S·ªë l∆∞·ª£ng nh√£n BIO:', len(bio_list))\n",
    "print(bio_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# T·∫°o m·ªôt t·ª´ ƒëi·ªÉn chuy·ªÉn ƒë·ªïi t·ª´ nh√£n BIO sang index v√† ng∆∞·ª£c l·∫°i\n",
    "bio2idx = {bio: idx for idx, bio in enumerate(bio_list)}\n",
    "idx2bio = {idx: bio for bio, idx in bio2idx.items()}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "S·ªë l∆∞·ª£ng nh√£n value: 143\n",
      "['train-departure none', 'hotel-area north', 'hotel-parking dontcare', 'train-destination london kings cross', 'hotel-pricerange moderate', 'hotel-pricerange none', 'attraction-type gastropub', 'hotel-area centre', 'attraction-type cinema', 'attraction-type museums', 'hotel-area dontcare', 'restaurant-area none', 'train-destination huntingdon marriott hotel', 'train-departure london liverpool', 'attraction-type hotel', 'train-destination curry prince', 'attraction-area south', 'train-departure norwich', 'hotel-type hotel', 'attraction-type concert hall', 'train-destination broxbourne', 'hotel-type guesthouse', 'train-destination kings lynn', 'attraction-type historical', 'attraction-type church', 'restaurant-area north', 'restaurant-area dontcare', 'hotel-pricerange expensive', 'hotel-internet dontcare', 'train-departure liverpool', 'attraction-type theatre', 'attraction-type dontcare', 'hotel-stars 1', 'train-destination stansted airport', 'restaurant-area west', 'hotel-stars 5', 'train-departure broxbourne', 'train-departure aylesbray lodge guest', 'attraction-type theater', 'attraction-type concert', 'train-departure stevenage', 'train-departure brookshite', 'attraction-area west', 'restaurant-area south', 'attraction-type gallery', 'train-departure birmingham new street', 'train-departure london liverpool street', 'hotel-area west', 'train-destination london liverpool street', 'hotel-pricerange cheap', 'bus-day none', 'hotel-stars none', 'attraction-type swimming pool', 'train-destination leicester', 'hotel-internet none', 'train-destination centre', 'attraction-type nightclub', 'restaurant-pricerange none', 'attraction-area centre', 'attraction-area north', 'train-destination city centre north', 'train-departure bishops stortford', 'attraction-type special', 'attraction-type camboats', 'train-departure dontcare', 'hotel-type none', 'attraction-type multiple sports', 'train-departure peterborough', 'hotel-area south', 'train-departure city hall', 'hotel-stars dontcare', 'train-destination glastonbury', 'hotel-pricerange dontcare', 'train-departure cambridge', 'bus-day wednesday', 'hotel-stars 0', 'train-destination ely', 'attraction-type museum kettles yard', 'train-destination norway', 'train-destination bishops stortford', 'restaurant-area centre', 'train-departure leicester', 'attraction-area dontcare', 'train-departure cineworld', 'hotel-internet yes', 'train-departure stansted airport', 'hotel-area east', 'attraction-type museum', 'train-departure wandlebury country park', 'train-departure huntingdon', 'attraction-type theatres', 'hotel-stars 3', 'hotel-type guest house', 'train-destination liverpool street', 'train-destination peterborough', 'attraction-type boat', 'attraction-type none', 'attraction-type pool', 'train-destination liverpool', 'hotel-stars 4', 'hotel-internet no', 'attraction-type night club', 'hotel-type bed and breakfast', 'attraction-area none', 'attraction-type entertainment', 'hotel-parking no', 'train-departure panahar', 'attraction-type hiking', 'train-departure kings lynn', 'hotel-type dontcare', 'train-destination dontcare', 'train-destination stevenage', 'train-departure london kings cross', 'train-departure ely', 'hotel-parking none', 'restaurant-pricerange expensive', 'restaurant-pricerange cheap', 'train-destination bournemouth', 'train-destination norwich', 'restaurant-pricerange moderate', 'hotel-stars 2', 'attraction-area east', 'attraction-type concerthall', 'attraction-type sports', 'attraction-type architecture', 'hotel-parking free', 'attraction-type college', 'train-departure east london', 'train-departure stratford', 'train-destination cambridge', 'hotel-area none', 'hotel-parking yes', 'train-departure duxford', 'train-departure london', 'restaurant-pricerange dontcare', 'train-destination london', 'restaurant-area east', 'attraction-type park', 'attraction-type cinemas', 'attraction-type churchills college', 'attraction-type boating', 'train-destination birmingham new street', 'train-destination none']\n"
     ]
    }
   ],
   "source": [
    "# T·∫°o nh√£n value cho c√°c slot ph√¢n lo·∫°i\n",
    "categorical_value_list = []\n",
    "\n",
    "for slot in categorical_slots:\n",
    "    for value in ontology[slot]:\n",
    "        for v in re.split(r'\\||>', value):\n",
    "            categorical_value_list.append(f'{slot} {v}')\n",
    "            \n",
    "categorical_value_list = list(set(categorical_value_list))\n",
    "print('S·ªë l∆∞·ª£ng nh√£n value:', len(categorical_value_list))\n",
    "print(categorical_value_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "cv2idx = {cv: idx for idx, cv in enumerate(categorical_value_list)}\n",
    "idx2cv = {idx: cv for cv, idx in cv2idx.items()}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenizer = AutoTokenizer.from_pretrained(\"distilbert-base-uncased\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "class MultiWozDataset(Dataset):\n",
    "    def __init__(self, dialogue_data, acts_data, tokenizer, act2idx, bio2idx, cv2idx, max_turn=-1, dialogue_ids=None):\n",
    "        self.data = self._process_data(\n",
    "            dialogue_data, acts_data, max_turn, dialogue_ids)\n",
    "        self.tokenizer = tokenizer\n",
    "        self.act2idx = act2idx\n",
    "        self.bio2idx = bio2idx\n",
    "        self.cv2idx = cv2idx\n",
    "        self.problem = 1 # 2, 3\n",
    "\n",
    "    def _process_data(self, dialogue_data, acts_data, max_turn, dialogue_ids):\n",
    "        data = []\n",
    "        for dialogue_id, dialogue in dialogue_data.items():\n",
    "            if dialogue_ids is not None and dialogue_id not in dialogue_ids:\n",
    "                continue\n",
    "            turns = dialogue['log']\n",
    "            history = []\n",
    "            for i in range(0, len(turns) - 1, 2):\n",
    "                user_turn = turns[i]\n",
    "                history.append(user_turn['text'])\n",
    "\n",
    "                system_turn = turns[i + 1]\n",
    "                history.append(system_turn['text'])\n",
    "\n",
    "                # L·∫•y act c·ªßa system\n",
    "                system_acts = acts_data[dialogue_id[:-5]\n",
    "                                        ].get(str(i//2 + 1), 'No Annotation')\n",
    "                if system_acts == 'No Annotation':\n",
    "                    system_acts = ['No Annotation']\n",
    "                else:\n",
    "                    system_acts = list(system_acts.keys())\n",
    "\n",
    "                # L·∫•y slot, value c·ªßa user\n",
    "                slot_values = []\n",
    "                for domain, domain_value in system_turn['metadata'].items():\n",
    "                    for slot, value in domain_value['book'].items():\n",
    "                        if slot == 'booked':\n",
    "                            continue\n",
    "                        if value and value != 'not mentioned':\n",
    "                            slot_values.append(\n",
    "                                [f'{domain}-book {slot}', value])\n",
    "                    for slot, value in domain_value['semi'].items():\n",
    "                        if value and value != 'not mentioned':\n",
    "                            slot_values.append([f'{domain}-{slot}', value])\n",
    "\n",
    "                data.append({\n",
    "                    'dialogue_id': dialogue_id,\n",
    "                    'history': history[max(0, i - 2 * max_turn):i] if max_turn > 0 else history[:i],\n",
    "                    'utterance': user_turn['text'],\n",
    "                    'system_acts': system_acts,\n",
    "                    'slot_values': slot_values\n",
    "                })\n",
    "        return data\n",
    "    \n",
    "    def set_problem(self, problem):\n",
    "        self.problem = problem\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.data)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        data = self.data[idx]\n",
    "\n",
    "        history_text = '[SEP]'.join(data['history'])\n",
    "        full_text = f'{history_text}[SEP]{data[\"utterance\"]}' if history_text else data['utterance']\n",
    "\n",
    "        # Tokenize text\n",
    "        encoding = self.tokenizer(full_text, return_tensors='pt')\n",
    "\n",
    "        if self.problem == 1:\n",
    "            act_labels = torch.zeros(len(self.act2idx))\n",
    "            for act in data['system_acts']:\n",
    "                act_labels[self.act2idx[act]] = 1\n",
    "            return {\n",
    "                'input_ids': encoding['input_ids'].squeeze(0),\n",
    "                'attention_mask': encoding['attention_mask'].squeeze(0),\n",
    "                'labels': act_labels\n",
    "            }\n",
    "\n",
    "        if self.problem == 2:\n",
    "            slot_labels = torch.tensor([self.bio2idx['O']] * len(encoding['input_ids'].squeeze(0)))\n",
    "            for slot, value in data['slot_values']:\n",
    "                if slot in non_categorical_slots:\n",
    "                    for v in re.split(r'\\||>', value):\n",
    "                        start, end = self._get_value_start_end(full_text, v)\n",
    "                        if start == 0 and end == 0:\n",
    "                            continue\n",
    "                        slot_labels[start] = self.bio2idx[f'B-{slot}']\n",
    "                        slot_labels[start + 1:end + 1] = self.bio2idx[f'I-{slot}']\n",
    "            # Chuy·ªÉn label c·ªßa [SEP] v√† [CLS] th√†nh -100\n",
    "            sep_idx = (encoding['input_ids'] == self.tokenizer.sep_token_id).nonzero(as_tuple=True)[1]\n",
    "            cls_idx = (encoding['input_ids'] == self.tokenizer.cls_token_id).nonzero(as_tuple=True)[1]\n",
    "            slot_labels[sep_idx] = -100\n",
    "            slot_labels[cls_idx] = -100\n",
    "            return {\n",
    "                'input_ids': encoding['input_ids'].squeeze(0),\n",
    "                'attention_mask': encoding['attention_mask'].squeeze(0),\n",
    "                'labels': slot_labels\n",
    "            }\n",
    "            \n",
    "        if self.problem == 3:\n",
    "            categorical_labels = torch.zeros(len(self.cv2idx))\n",
    "            for slot, value in data['slot_values']:\n",
    "                if slot in categorical_slots:\n",
    "                    for v in re.split(r'\\||>', value):\n",
    "                        categorical_labels[self.cv2idx[f'{slot} {v}']] = 1\n",
    "            return {\n",
    "                'input_ids': encoding['input_ids'].squeeze(0),\n",
    "                'attention_mask': encoding['attention_mask'].squeeze(0),\n",
    "                'labels': categorical_labels\n",
    "            }\n",
    "\n",
    "    def _get_value_start_end(self, text, value):\n",
    "        tokenized_text = self.tokenizer.tokenize(text, add_special_tokens=True)\n",
    "        tokenized_value = self.tokenizer.tokenize(value)\n",
    "\n",
    "        start, end = 0, 0\n",
    "        for id_v, token_v in enumerate(tokenized_value):\n",
    "            for id_u, token_u in enumerate(tokenized_text):\n",
    "                if token_v == token_u:\n",
    "                    # n·∫øu value ƒë∆∞·ª£c t√¨m th·∫•y trong text\n",
    "                    if tokenized_value == tokenized_text[id_u:id_u+len(tokenized_value)]:\n",
    "                        start, end = id_u, id_u+len(tokenized_value) - 1\n",
    "                        break\n",
    "                    # n·∫øu s·ªë l∆∞·ª£ng token c√≤n l·∫°i trong text √≠t h∆°n s·ªë l∆∞·ª£ng token c·ªßa value\n",
    "                    elif len(tokenized_text) - id_u + 1 <= len(tokenized_value):\n",
    "                        break\n",
    "        return torch.tensor([start, end])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dataset = MultiWozDataset(data, dialogue_acts, tokenizer, act2idx, bio2idx, cv2idx, max_turn=3, dialogue_ids=train_list)\n",
    "val_dataset = MultiWozDataset(data, dialogue_acts, tokenizer, act2idx, bio2idx, cv2idx, max_turn=3, dialogue_ids=val_list)\n",
    "test_dataset = MultiWozDataset(data, dialogue_acts, tokenizer, act2idx, bio2idx, cv2idx, max_turn=3, dialogue_ids=test_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_collator = DataCollatorWithPadding(tokenizer)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## M√¥ h√¨nh ph√°t hi·ªán system acts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "clf_metrics = evaluate.combine([\"accuracy\", \"f1\", \"precision\", \"recall\"])\n",
    "\n",
    "\n",
    "def sigmoid(x):\n",
    "    return 1/(1 + np.exp(-x))\n",
    "\n",
    "\n",
    "def compute_metrics(eval_pred):\n",
    "    predictions, labels = eval_pred\n",
    "    predictions = sigmoid(predictions)\n",
    "    predictions = (predictions > 0.5).astype(int).reshape(-1)\n",
    "    return clf_metrics.compute(predictions=predictions, references=labels.astype(int).reshape(-1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of DistilBertForSequenceClassification were not initialized from the model checkpoint at distilbert-base-uncased and are newly initialized: ['classifier.bias', 'classifier.weight', 'pre_classifier.bias', 'pre_classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "/home/aircsrv5/miniconda3/envs/imlda/lib/python3.10/site-packages/transformers/training_args.py:1568: FutureWarning: `evaluation_strategy` is deprecated and will be removed in version 4.46 of ü§ó Transformers. Use `eval_strategy` instead\n",
      "  warnings.warn(\n",
      "/tmp/ipykernel_44333/804699869.py:15: FutureWarning: `tokenizer` is deprecated and will be removed in version 5.0.0 for `Trainer.__init__`. Use `processing_class` instead.\n",
      "  trainer = Trainer(\n"
     ]
    }
   ],
   "source": [
    "system_acts_model = AutoModelForSequenceClassification.from_pretrained('distilbert-base-uncased', num_labels = len(acts) , id2label=idx2act, label2id=act2idx, problem_type='multi_label_classification')\n",
    "\n",
    "training_args = TrainingArguments(\n",
    "   output_dir=\"model/system_acts_model\",\n",
    "   learning_rate=2e-5,\n",
    "   per_device_train_batch_size=16,\n",
    "   per_device_eval_batch_size=16,\n",
    "   num_train_epochs=3,\n",
    "   weight_decay=0.01,\n",
    "   evaluation_strategy=\"epoch\",\n",
    "   save_strategy=\"epoch\",\n",
    "   load_best_model_at_end=True,\n",
    ")\n",
    "\n",
    "trainer = Trainer(\n",
    "   model=system_acts_model,\n",
    "   args=training_args,\n",
    "   train_dataset=train_dataset,\n",
    "   eval_dataset=val_dataset,\n",
    "   tokenizer=tokenizer,\n",
    "   data_collator=data_collator,\n",
    "   compute_metrics=compute_metrics,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='10647' max='10647' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [10647/10647 08:15, Epoch 3/3]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Epoch</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>F1</th>\n",
       "      <th>Precision</th>\n",
       "      <th>Recall</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>0.083300</td>\n",
       "      <td>0.078936</td>\n",
       "      <td>0.968127</td>\n",
       "      <td>0.611298</td>\n",
       "      <td>0.748323</td>\n",
       "      <td>0.516687</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>0.078200</td>\n",
       "      <td>0.074162</td>\n",
       "      <td>0.969941</td>\n",
       "      <td>0.649953</td>\n",
       "      <td>0.746853</td>\n",
       "      <td>0.575310</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>0.073100</td>\n",
       "      <td>0.073017</td>\n",
       "      <td>0.970237</td>\n",
       "      <td>0.656728</td>\n",
       "      <td>0.745368</td>\n",
       "      <td>0.586930</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "TrainOutput(global_step=10647, training_loss=0.08661638990617015, metrics={'train_runtime': 495.9088, 'train_samples_per_second': 343.478, 'train_steps_per_second': 21.47, 'total_flos': 7296220874484864.0, 'train_loss': 0.08661638990617015, 'epoch': 3.0})"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trainer.train()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "trainer.save_model()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='2' max='461' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [  2/461 00:00 < 00:06, 76.42 it/s]\n",
       "    </div>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 0.07333177328109741, 'eval_accuracy': 0.9704625610417797, 'eval_f1': 0.6582973715182424, 'eval_precision': 0.7468565706019806, 'eval_recall': 0.5885138097325734, 'eval_runtime': 7.5121, 'eval_samples_per_second': 981.345, 'eval_steps_per_second': 61.367, 'epoch': 3.0}\n"
     ]
    }
   ],
   "source": [
    "# Th·ª≠ nghi·ªám tr√™n t·∫≠p test\n",
    "print(trainer.evaluate(test_dataset))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "system_acts_classifier = pipeline('text-classification', model='model/system_acts_model', device=0, top_k=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "I need train reservations from norwich to cambridge\n",
      "['Train-Request']\n",
      "I have 133 trains matching your request. Is there a specific day and time you would like to travel?\n",
      "I'd like to leave on Monday and arrive by 18:00.\n",
      "['Train-Request']\n",
      "There are 12 trains for the day and time you request.  Would you like to book it now?\n",
      "Before booking, I would also like to know the travel time, price, and departure time please.\n",
      "['Train-Inform']\n",
      "There are 12 trains meeting your needs with the first leaving at 05:16 and the last one leaving at 16:16. Do you want to book one of these? \n",
      "No hold off on booking for now.  Can you help me find an attraction called cineworld cinema?\n",
      "['Attraction-Inform', 'general-reqmore']\n",
      "Yes it is a cinema located in the south part of town what information would you like on it?\n",
      "Yes, that was all I needed. Thank you very much!\n",
      "['general-bye']\n",
      "Thank you for using our system.\n"
     ]
    }
   ],
   "source": [
    "sample_text = [\n",
    "    \"I need train reservations from norwich to cambridge\",\n",
    "    \"I have 133 trains matching your request. Is there a specific day and time you would like to travel?\",\n",
    "    \"I'd like to leave on Monday and arrive by 18:00.\",\n",
    "    \"There are 12 trains for the day and time you request.  Would you like to book it now?\",\n",
    "    \"Before booking, I would also like to know the travel time, price, and departure time please.\",\n",
    "    \"There are 12 trains meeting your needs with the first leaving at 05:16 and the last one leaving at 16:16. Do you want to book one of these? \",\n",
    "    \"No hold off on booking for now.  Can you help me find an attraction called cineworld cinema?\",\n",
    "    \"Yes it is a cinema located in the south part of town what information would you like on it?\",\n",
    "    \"Yes, that was all I needed. Thank you very much!\",\n",
    "    \"Thank you for using our system.\"\n",
    "]\n",
    "\n",
    "history = []\n",
    "max_turn = 3\n",
    "threshold = 0.5\n",
    "for turn in range(0, len(sample_text) - 1, 2):\n",
    "    history_text = '[SEP]'.join(history[max(0, turn - 2 * max_turn):turn])\n",
    "    full_text = f'{history_text}[SEP]{sample_text[turn]}' if history_text else sample_text[turn]\n",
    "    print(sample_text[turn])\n",
    "    print([out['label'] for out in system_acts_classifier(full_text)[0] if out['score'] > threshold])\n",
    "    print(sample_text[turn + 1])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## M√¥ h√¨nh ph√°t hi·ªán slot value"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### V·ªõi slot ph√¢n lo·∫°i"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_collator_for_cv = DataCollatorWithPadding(tokenizer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dataset.set_problem(3)\n",
    "val_dataset.set_problem(3)\n",
    "test_dataset.set_problem(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of DistilBertForSequenceClassification were not initialized from the model checkpoint at distilbert-base-uncased and are newly initialized: ['classifier.bias', 'classifier.weight', 'pre_classifier.bias', 'pre_classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "/home/aircsrv5/miniconda3/envs/imlda/lib/python3.10/site-packages/transformers/training_args.py:1568: FutureWarning: `evaluation_strategy` is deprecated and will be removed in version 4.46 of ü§ó Transformers. Use `eval_strategy` instead\n",
      "  warnings.warn(\n",
      "/tmp/ipykernel_44333/3317102083.py:15: FutureWarning: `tokenizer` is deprecated and will be removed in version 5.0.0 for `Trainer.__init__`. Use `processing_class` instead.\n",
      "  trainer_cv = Trainer(\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='17745' max='17745' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [17745/17745 14:13, Epoch 5/5]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Epoch</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>F1</th>\n",
       "      <th>Precision</th>\n",
       "      <th>Recall</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>0.041800</td>\n",
       "      <td>0.049127</td>\n",
       "      <td>0.985502</td>\n",
       "      <td>0.487118</td>\n",
       "      <td>0.774152</td>\n",
       "      <td>0.355360</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>0.030500</td>\n",
       "      <td>0.042078</td>\n",
       "      <td>0.989745</td>\n",
       "      <td>0.686968</td>\n",
       "      <td>0.840606</td>\n",
       "      <td>0.580813</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>0.025500</td>\n",
       "      <td>0.041252</td>\n",
       "      <td>0.990556</td>\n",
       "      <td>0.716696</td>\n",
       "      <td>0.855600</td>\n",
       "      <td>0.616593</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>0.023200</td>\n",
       "      <td>0.042296</td>\n",
       "      <td>0.990708</td>\n",
       "      <td>0.723673</td>\n",
       "      <td>0.853740</td>\n",
       "      <td>0.627998</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5</td>\n",
       "      <td>0.021500</td>\n",
       "      <td>0.043085</td>\n",
       "      <td>0.990738</td>\n",
       "      <td>0.726115</td>\n",
       "      <td>0.850043</td>\n",
       "      <td>0.633725</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "TrainOutput(global_step=17745, training_loss=0.03461599121566691, metrics={'train_runtime': 853.9469, 'train_samples_per_second': 332.445, 'train_steps_per_second': 20.78, 'total_flos': 1.2178201492754736e+16, 'train_loss': 0.03461599121566691, 'epoch': 5.0})"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "categorical_value_model = AutoModelForSequenceClassification.from_pretrained('distilbert-base-uncased', num_labels = len(categorical_value_list), id2label=idx2cv, label2id=cv2idx, problem_type='multi_label_classification')\n",
    "\n",
    "training_args_cv = TrainingArguments(\n",
    "   output_dir=\"model/categorical_value_model\",\n",
    "   learning_rate=2e-5,\n",
    "   per_device_train_batch_size=16,\n",
    "   per_device_eval_batch_size=16,\n",
    "   num_train_epochs=5,\n",
    "   weight_decay=0.01,\n",
    "   evaluation_strategy=\"epoch\",\n",
    "   save_strategy=\"epoch\",\n",
    "   load_best_model_at_end=True,\n",
    ")\n",
    "\n",
    "trainer_cv = Trainer(\n",
    "   model=categorical_value_model,\n",
    "   args=training_args_cv,\n",
    "   train_dataset=train_dataset,\n",
    "   eval_dataset=val_dataset,\n",
    "   tokenizer=tokenizer,\n",
    "   data_collator=data_collator_for_cv,\n",
    "   compute_metrics=compute_metrics,\n",
    ")\n",
    "\n",
    "trainer_cv.train()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "trainer_cv.save_model()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='2' max='461' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [  2/461 00:00 < 00:06, 74.55 it/s]\n",
       "    </div>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "{'eval_loss': 0.03925233706831932,\n",
       " 'eval_accuracy': 0.9907237363829876,\n",
       " 'eval_f1': 0.7162134710815752,\n",
       " 'eval_precision': 0.8506238367684567,\n",
       " 'eval_recall': 0.6184843624699278,\n",
       " 'eval_runtime': 12.2403,\n",
       " 'eval_samples_per_second': 602.273,\n",
       " 'eval_steps_per_second': 37.662,\n",
       " 'epoch': 5.0}"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trainer_cv.evaluate(test_dataset)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### V·ªõi slot kh√¥ng ph√¢n lo·∫°i"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dataset.set_problem(2)\n",
    "val_dataset.set_problem(2)\n",
    "test_dataset.set_problem(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_collator = DataCollatorForTokenClassification(tokenizer=tokenizer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "seqeval = evaluate.load(\"seqeval\")\n",
    "\n",
    "def compute_metrics_tf(p):\n",
    "    predictions, labels = p\n",
    "    predictions = np.argmax(predictions, axis=2)\n",
    "\n",
    "    true_predictions = [\n",
    "        [idx2bio[p] for (p, l) in zip(prediction, label) if l != -100]\n",
    "        for prediction, label in zip(predictions, labels)\n",
    "    ]\n",
    "    true_labels = [\n",
    "        [idx2bio[l] for (p, l) in zip(prediction, label) if l != -100]\n",
    "        for prediction, label in zip(predictions, labels)\n",
    "    ]\n",
    "\n",
    "    results = seqeval.compute(predictions=true_predictions, references=true_labels)\n",
    "    return {\n",
    "        \"precision\": results[\"overall_precision\"],\n",
    "        \"recall\": results[\"overall_recall\"],\n",
    "        \"f1\": results[\"overall_f1\"],\n",
    "        \"accuracy\": results[\"overall_accuracy\"],\n",
    "    }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of DistilBertForTokenClassification were not initialized from the model checkpoint at distilbert/distilbert-base-uncased and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    }
   ],
   "source": [
    "non_categorical_value_model = AutoModelForTokenClassification.from_pretrained(\n",
    "    \"distilbert/distilbert-base-uncased\", num_labels=len(bio_list), id2label=idx2bio, label2id=bio2idx\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='10647' max='10647' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [10647/10647 10:06, Epoch 3/3]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Epoch</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Precision</th>\n",
       "      <th>Recall</th>\n",
       "      <th>F1</th>\n",
       "      <th>Accuracy</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>0.028000</td>\n",
       "      <td>0.022622</td>\n",
       "      <td>0.862630</td>\n",
       "      <td>0.888311</td>\n",
       "      <td>0.875282</td>\n",
       "      <td>0.992512</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>0.021100</td>\n",
       "      <td>0.020227</td>\n",
       "      <td>0.884951</td>\n",
       "      <td>0.902272</td>\n",
       "      <td>0.893528</td>\n",
       "      <td>0.993210</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>0.017200</td>\n",
       "      <td>0.020228</td>\n",
       "      <td>0.893529</td>\n",
       "      <td>0.906310</td>\n",
       "      <td>0.899874</td>\n",
       "      <td>0.993514</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/aircsrv5/miniconda3/envs/imlda/lib/python3.10/site-packages/seqeval/metrics/v1.py:57: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/home/aircsrv5/miniconda3/envs/imlda/lib/python3.10/site-packages/seqeval/metrics/v1.py:57: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "TrainOutput(global_step=10647, training_loss=0.03109562422755157, metrics={'train_runtime': 606.6708, 'train_samples_per_second': 280.768, 'train_steps_per_second': 17.55, 'total_flos': 7198554702861252.0, 'train_loss': 0.03109562422755157, 'epoch': 3.0})"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "training_args_ncv = TrainingArguments(\n",
    "    output_dir=\"model/non_categorical_value_model\",\n",
    "    learning_rate=2e-5,\n",
    "    per_device_train_batch_size=16,\n",
    "    per_device_eval_batch_size=16,\n",
    "    num_train_epochs=3,\n",
    "    weight_decay=0.01,\n",
    "    eval_strategy=\"epoch\",\n",
    "    save_strategy=\"epoch\",\n",
    "    load_best_model_at_end=True,\n",
    ")\n",
    "\n",
    "trainer_ncv = Trainer(\n",
    "    model=non_categorical_value_model,\n",
    "    args=training_args_ncv,\n",
    "    train_dataset=train_dataset,\n",
    "    eval_dataset=val_dataset,\n",
    "    processing_class=tokenizer,\n",
    "    data_collator=data_collator,\n",
    "    compute_metrics=compute_metrics_tf,\n",
    ")\n",
    "\n",
    "trainer_ncv.train()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "trainer_ncv.save_model()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='1' max='461' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [  1/461 : < :]\n",
       "    </div>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "{'eval_loss': 0.019612910225987434,\n",
       " 'eval_precision': 0.8848949919224556,\n",
       " 'eval_recall': 0.9061207609594706,\n",
       " 'eval_f1': 0.8953821005312628,\n",
       " 'eval_accuracy': 0.9936638199352084,\n",
       " 'eval_runtime': 15.0322,\n",
       " 'eval_samples_per_second': 490.415,\n",
       " 'eval_steps_per_second': 30.668,\n",
       " 'epoch': 3.0}"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trainer_ncv.evaluate(test_dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "categorical_value_clf = pipeline('text-classification', model='model/categorical_value_model', device=0, top_k=None)\n",
    "non_categorical_value_tclf = pipeline('ner', model='model/non_categorical_value_model', device=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "def slot_vlaue_predict(full_text):\n",
    "    state = defaultdict(list)\n",
    "    categorical_value_result = categorical_value_clf(full_text)\n",
    "    non_categorical_value_result = non_categorical_value_tclf(full_text)\n",
    "    \n",
    "    for out in categorical_value_result[0]:\n",
    "        if out['score'] > 0.5:\n",
    "            slot, value = out['label'].split(' ', 1)\n",
    "            state[slot].append(value)\n",
    "            \n",
    "    current_entity = None\n",
    "    current_value = \"\"\n",
    "    \n",
    "    for item in non_categorical_value_result:\n",
    "        entity_type = item['entity'][2:]  # Remove the B- or I- prefix\n",
    "        if item['entity'].startswith('B-'):\n",
    "            if current_entity:  # Save the previous entity-value pair if exists\n",
    "                if current_value.find(':') != -1:\n",
    "                    current_value = current_value.replace(' ', '')\n",
    "                state[current_entity].append(current_value)\n",
    "            current_entity = entity_type\n",
    "            current_value = item['word']\n",
    "        elif item['entity'].startswith('I-') and current_entity == entity_type:\n",
    "            if item['word'].startswith('##'):\n",
    "                current_value += item['word'][2:]\n",
    "            else:\n",
    "                current_value += ' ' + item['word']  # Concatenate words for the same entity\n",
    "\n",
    "    # Append the last entity-value pair\n",
    "    if current_entity:\n",
    "        if current_value.find(':') != -1:\n",
    "            current_value = current_value.replace(' ', '')\n",
    "        state[current_entity].append(current_value)\n",
    "        \n",
    "    return state"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "I need train reservations from norwich to cambridge\n",
      "{'train-destination': ['cambridge'], 'train-departure': ['norwich']}\n",
      "I have 133 trains matching your request. Is there a specific day and time you would like to travel?\n",
      "I'd like to leave on Monday and arrive by 18:00.\n",
      "{'train-destination': ['cambridge'], 'train-departure': ['norwich'], 'train-day': ['monday'], 'train-arriveBy': ['18:00']}\n",
      "There are 12 trains for the day and time you request.  Would you like to book it now?\n",
      "Before booking, I would also like to know the travel time, price, and departure time please.\n",
      "{'train-destination': ['cambridge'], 'train-departure': ['cambridge'], 'train-day': ['monday'], 'train-arriveBy': ['18:00']}\n",
      "There are 12 trains meeting your needs with the first leaving at 05:16 and the last one leaving at 16:16. Do you want to book one of these? \n",
      "No hold off on booking for now.  Can you help me find an attraction called cineworld cinema?\n",
      "{'train-destination': ['cambridge'], 'train-departure': ['cambridge'], 'train-day': ['monday'], 'train-arriveBy': ['18:00'], 'attraction-name': ['cineworld cinema']}\n",
      "Yes it is a cinema located in the south part of town what information would you like on it?\n",
      "Yes, that was all I needed. Thank you very much!\n",
      "{'train-destination': ['cambridge'], 'train-departure': ['cambridge'], 'train-day': ['monday'], 'train-arriveBy': ['18:00'], 'attraction-name': ['cineworld cinema']}\n",
      "Thank you for using our system.\n"
     ]
    }
   ],
   "source": [
    "state = {}\n",
    "max_turn = 3\n",
    "for turn in range(0, len(sample_text) - 1, 2):\n",
    "    history_text = '[SEP]'.join(history[max(0, turn - 2 * max_turn):turn])\n",
    "    full_text = f'{history_text}[SEP]{sample_text[turn]}' if history_text else sample_text[turn]\n",
    "    print(sample_text[turn])\n",
    "    state = dict(state | slot_vlaue_predict(full_text))\n",
    "    print(state)\n",
    "    print(sample_text[turn + 1])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ml",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.15"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
