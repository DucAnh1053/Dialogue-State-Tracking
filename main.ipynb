{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from transformers import BertTokenizer, BertModel, AutoTokenizer\n",
    "import json\n",
    "import numpy as np\n",
    "from collections import defaultdict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_path = \"MultiWOZ2.4-main/data/mwz2.4/train_dials.json\"\n",
    "dev_path = \"MultiWOZ2.4-main/data/mwz2.4/dev_dials.json\"\n",
    "test_path = \"MultiWOZ2.4-main/data/mwz2.4/test_dials.json\"\n",
    "\n",
    "with open(train_path, 'r') as f:\n",
    "    train_data = json.load(f)\n",
    "    \n",
    "with open(dev_path, 'r') as f:\n",
    "    dev_data = json.load(f)\n",
    "\n",
    "with open(test_path, 'r') as f:\n",
    "    test_data = json.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(8420, 1000, 999)"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(train_data), len(dev_data), len(test_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "labels = set()\n",
    "\n",
    "for dialouge in train_data:\n",
    "    for turn in dialouge['dialogue']:\n",
    "        for key, _ in turn['turn_label']:\n",
    "            labels.add(key)\n",
    "            \n",
    "for dialouge in dev_data:\n",
    "    for turn in dialouge['dialogue']:\n",
    "        for key, _ in turn['turn_label']:\n",
    "            labels.add(key)\n",
    "            \n",
    "for dialouge in test_data:\n",
    "    for turn in dialouge['dialogue']:\n",
    "        for key, _ in turn['turn_label']:\n",
    "            labels.add(key)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "31"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'attraction-area',\n",
       " 'attraction-name',\n",
       " 'attraction-type',\n",
       " 'hospital-department',\n",
       " 'hotel-area',\n",
       " 'hotel-book day',\n",
       " 'hotel-book people',\n",
       " 'hotel-book stay',\n",
       " 'hotel-internet',\n",
       " 'hotel-name',\n",
       " 'hotel-parking',\n",
       " 'hotel-pricerange',\n",
       " 'hotel-stars',\n",
       " 'hotel-type',\n",
       " 'restaurant-area',\n",
       " 'restaurant-book day',\n",
       " 'restaurant-book people',\n",
       " 'restaurant-book time',\n",
       " 'restaurant-food',\n",
       " 'restaurant-name',\n",
       " 'restaurant-pricerange',\n",
       " 'taxi-arriveby',\n",
       " 'taxi-departure',\n",
       " 'taxi-destination',\n",
       " 'taxi-leaveat',\n",
       " 'train-arriveby',\n",
       " 'train-book people',\n",
       " 'train-day',\n",
       " 'train-departure',\n",
       " 'train-destination',\n",
       " 'train-leaveat'}"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['O',\n",
       " 'B-hotel-pricerange',\n",
       " 'I-hotel-pricerange',\n",
       " 'B-train-destination',\n",
       " 'I-train-destination',\n",
       " 'B-restaurant-book time',\n",
       " 'I-restaurant-book time',\n",
       " 'B-hotel-parking',\n",
       " 'I-hotel-parking',\n",
       " 'B-restaurant-name',\n",
       " 'I-restaurant-name',\n",
       " 'B-hotel-area',\n",
       " 'I-hotel-area',\n",
       " 'B-restaurant-area',\n",
       " 'I-restaurant-area',\n",
       " 'B-train-book people',\n",
       " 'I-train-book people',\n",
       " 'B-hotel-book stay',\n",
       " 'I-hotel-book stay',\n",
       " 'B-restaurant-pricerange',\n",
       " 'I-restaurant-pricerange',\n",
       " 'B-train-departure',\n",
       " 'I-train-departure',\n",
       " 'B-attraction-type',\n",
       " 'I-attraction-type',\n",
       " 'B-hotel-book people',\n",
       " 'I-hotel-book people',\n",
       " 'B-taxi-departure',\n",
       " 'I-taxi-departure',\n",
       " 'B-train-leaveat',\n",
       " 'I-train-leaveat',\n",
       " 'B-attraction-area',\n",
       " 'I-attraction-area',\n",
       " 'B-taxi-destination',\n",
       " 'I-taxi-destination',\n",
       " 'B-restaurant-book people',\n",
       " 'I-restaurant-book people',\n",
       " 'B-restaurant-book day',\n",
       " 'I-restaurant-book day',\n",
       " 'B-restaurant-food',\n",
       " 'I-restaurant-food',\n",
       " 'B-hospital-department',\n",
       " 'I-hospital-department',\n",
       " 'B-attraction-name',\n",
       " 'I-attraction-name',\n",
       " 'B-taxi-leaveat',\n",
       " 'I-taxi-leaveat',\n",
       " 'B-hotel-internet',\n",
       " 'I-hotel-internet',\n",
       " 'B-hotel-name',\n",
       " 'I-hotel-name',\n",
       " 'B-hotel-stars',\n",
       " 'I-hotel-stars',\n",
       " 'B-hotel-book day',\n",
       " 'I-hotel-book day',\n",
       " 'B-train-arriveby',\n",
       " 'I-train-arriveby',\n",
       " 'B-train-day',\n",
       " 'I-train-day',\n",
       " 'B-hotel-type',\n",
       " 'I-hotel-type',\n",
       " 'B-taxi-arriveby',\n",
       " 'I-taxi-arriveby']"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "label_list = ['O']\n",
    "label_list.extend([item for slot in labels for item in [f'B-{slot}', f'I-{slot}']])\n",
    "label_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "label2idx = {label: idx for idx, label in enumerate(label_list)}\n",
    "idx2label = {idx: label for label, idx in label2idx.items()}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenizer = AutoTokenizer.from_pretrained(\"distilbert-base-uncased\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_value_from_utterance(utterance, value):\n",
    "    tokenized_utterance = tokenizer.tokenize(utterance, add_special_tokens=True)\n",
    "    # print(tokenized_utterance)\n",
    "    tokenized_value = tokenizer.tokenize(value)\n",
    "    # print(tokenized_value)\n",
    "\n",
    "    start, end = 0, 0\n",
    "    for id_v, token_v in enumerate(tokenized_value):\n",
    "        for id_u, token_u in enumerate(tokenized_utterance):\n",
    "            if token_v == token_u:\n",
    "                # if the value is found in the utterance\n",
    "                if tokenized_value == tokenized_utterance[id_u:id_u+len(tokenized_value)]:\n",
    "                    start, end = id_u, id_u+len(tokenized_value) - 1\n",
    "                    break\n",
    "                # if the remaining tokens in utterance is less than the value\n",
    "                elif len(tokenized_utterance) - id_u + 1 <= len(tokenized_value):\n",
    "                    break\n",
    "    return torch.tensor([start, end])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "class MultiWOZDataset(Dataset):\n",
    "    def __init__(self, data, tokenizer, label2idx, idx2label):\n",
    "        self.data = data\n",
    "        self.tokenizer = tokenizer\n",
    "        self.label2idx = label2idx\n",
    "        self.idx2label = idx2label\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.data)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        dialouge = self.data[idx]\n",
    "        turn = dialouge['dialogue'][0]  # only the first turn is considered\n",
    "        utterance = turn['transcript']\n",
    "        results = self.tokenizer(\n",
    "            utterance,  return_tensors=\"pt\", truncation=True)\n",
    "        labels = torch.tensor([self.label2idx['O']] * len(results['input_ids'].flatten()))\n",
    "        for slot, value in turn['turn_label']:\n",
    "            start, end = get_value_from_utterance(utterance, value)\n",
    "            labels[start] = self.label2idx[f'B-{slot}']\n",
    "            labels[start+1:end+1] = self.label2idx[f'I-{slot}']\n",
    "        labels[0] = -100  # CLS token\n",
    "        labels[-1] = -100 # SEP token\n",
    "\n",
    "        return {\n",
    "            'input_ids': results['input_ids'].flatten(),\n",
    "            'attention_mask': results['attention_mask'].flatten(),\n",
    "            'labels': labels\n",
    "        }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dataset = MultiWOZDataset(train_data, tokenizer, label2idx, idx2label)\n",
    "dev_dataset = MultiWOZDataset(dev_data, tokenizer, label2idx, idx2label)\n",
    "test_dataset = MultiWOZDataset(test_data, tokenizer, label2idx, idx2label)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import DataCollatorForTokenClassification\n",
    "\n",
    "data_collator = DataCollatorForTokenClassification(tokenizer=tokenizer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "import evaluate\n",
    "\n",
    "seqeval = evaluate.load(\"seqeval\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_metrics(p):\n",
    "    predictions, labels = p\n",
    "    predictions = np.argmax(predictions, axis=2)\n",
    "\n",
    "    true_predictions = [\n",
    "        [idx2label[p] for (p, l) in zip(prediction, label) if l != -100]\n",
    "        for prediction, label in zip(predictions, labels)\n",
    "    ]\n",
    "    true_labels = [\n",
    "        [idx2label[l] for (p, l) in zip(prediction, label) if l != -100]\n",
    "        for prediction, label in zip(predictions, labels)\n",
    "    ]\n",
    "\n",
    "    results = seqeval.compute(predictions=true_predictions, references=true_labels)\n",
    "    return {\n",
    "        \"precision\": results[\"overall_precision\"],\n",
    "        \"recall\": results[\"overall_recall\"],\n",
    "        \"f1\": results[\"overall_f1\"],\n",
    "        \"accuracy\": results[\"overall_accuracy\"],\n",
    "    }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'label_list' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[1], line 4\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mtransformers\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m AutoModelForTokenClassification, TrainingArguments, Trainer\n\u001b[0;32m      3\u001b[0m model \u001b[38;5;241m=\u001b[39m AutoModelForTokenClassification\u001b[38;5;241m.\u001b[39mfrom_pretrained(\n\u001b[1;32m----> 4\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mdistilbert/distilbert-base-uncased\u001b[39m\u001b[38;5;124m\"\u001b[39m, num_labels\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mlen\u001b[39m(\u001b[43mlabel_list\u001b[49m), id2label\u001b[38;5;241m=\u001b[39midx2label, label2id\u001b[38;5;241m=\u001b[39mlabel2idx\n\u001b[0;32m      5\u001b[0m )\n",
      "\u001b[1;31mNameError\u001b[0m: name 'label_list' is not defined"
     ]
    }
   ],
   "source": [
    "from transformers import AutoModelForTokenClassification, TrainingArguments, Trainer\n",
    "\n",
    "model = AutoModelForTokenClassification.from_pretrained(\n",
    "    \"distilbert/distilbert-base-uncased\", num_labels=len(label_list), id2label=idx2label, label2id=label2idx\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "12c992b59034475186e7326ae2040e35",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1054 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 0.3262, 'grad_norm': 1.0806093215942383, 'learning_rate': 1.0512333965844403e-05, 'epoch': 0.95}\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5fa5789029724157913cae04ac9fc334",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/63 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\DucAnh\\miniconda3\\envs\\ml\\lib\\site-packages\\seqeval\\metrics\\v1.py:57: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 0.10356897115707397, 'eval_precision': 0.8090778097982709, 'eval_recall': 0.861857252494244, 'eval_f1': 0.8346339650687478, 'eval_accuracy': 0.9734402405412177, 'eval_runtime': 2.2691, 'eval_samples_per_second': 440.7, 'eval_steps_per_second': 27.764, 'epoch': 1.0}\n",
      "{'loss': 0.0789, 'grad_norm': 0.30119651556015015, 'learning_rate': 1.0246679316888046e-06, 'epoch': 1.9}\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9ea32e3a442a44b7b3ac2d2a30ea6224",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/63 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\DucAnh\\miniconda3\\envs\\ml\\lib\\site-packages\\seqeval\\metrics\\v1.py:57: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 0.06719104200601578, 'eval_precision': 0.8944610778443114, 'eval_recall': 0.9171143514965464, 'eval_f1': 0.9056460780598712, 'eval_accuracy': 0.9844650463542972, 'eval_runtime': 3.138, 'eval_samples_per_second': 318.67, 'eval_steps_per_second': 20.076, 'epoch': 2.0}\n",
      "{'train_runtime': 117.4161, 'train_samples_per_second': 143.422, 'train_steps_per_second': 8.977, 'train_loss': 0.19537621001364835, 'epoch': 2.0}\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "TrainOutput(global_step=1054, training_loss=0.19537621001364835, metrics={'train_runtime': 117.4161, 'train_samples_per_second': 143.422, 'train_steps_per_second': 8.977, 'total_flos': 126543229774920.0, 'train_loss': 0.19537621001364835, 'epoch': 2.0})"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "training_args = TrainingArguments(\n",
    "    output_dir=\"./results\",\n",
    "    learning_rate=2e-5,\n",
    "    per_device_train_batch_size=16,\n",
    "    per_device_eval_batch_size=16,\n",
    "    num_train_epochs=2,\n",
    "    weight_decay=0.01,\n",
    "    eval_strategy=\"epoch\",\n",
    "    save_strategy=\"epoch\",\n",
    "    load_best_model_at_end=True,\n",
    ")\n",
    "\n",
    "trainer = Trainer(\n",
    "    model=model,\n",
    "    args=training_args,\n",
    "    train_dataset=train_dataset,\n",
    "    eval_dataset=dev_dataset,\n",
    "    processing_class=tokenizer,\n",
    "    data_collator=data_collator,\n",
    "    compute_metrics=compute_metrics,\n",
    ")\n",
    "\n",
    "trainer.train()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ad5a08e0e5b54abdb8b8a124c8c04f02",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/63 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 0.06670460850000381, 'eval_precision': 0.8960739030023095, 'eval_recall': 0.9107981220657277, 'eval_f1': 0.9033760186263097, 'eval_accuracy': 0.9844116342437108, 'eval_runtime': 2.3019, 'eval_samples_per_second': 433.981, 'eval_steps_per_second': 27.368, 'epoch': 2.0}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\DucAnh\\miniconda3\\envs\\ml\\lib\\site-packages\\seqeval\\metrics\\v1.py:57: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    }
   ],
   "source": [
    "results = trainer.evaluate(test_dataset)\n",
    "print(results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Hardware accelerator e.g. GPU is available in the environment, but no `device` argument is passed to the `Pipeline` object. Model will be on CPU.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[{'entity': 'B-hotel-pricerange',\n",
       "  'score': np.float32(0.95633507),\n",
       "  'index': 11,\n",
       "  'word': 'cheap',\n",
       "  'start': 43,\n",
       "  'end': 48},\n",
       " {'entity': 'B-hotel-type',\n",
       "  'score': np.float32(0.4760056),\n",
       "  'index': 21,\n",
       "  'word': 'hotel',\n",
       "  'start': 87,\n",
       "  'end': 92}]"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from transformers import pipeline\n",
    "\n",
    "classifier = pipeline(\"ner\", model=\"./results/checkpoint-1054\")\n",
    "classifier(\"am looking for a place to to stay that has cheap price range it should be in a type of hotel\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict(utterance):\n",
    "    slots = []\n",
    "    results = classifier(utterance)\n",
    "    \n",
    "    current_entity = None\n",
    "    current_value = \"\"\n",
    "    \n",
    "    for item in results:\n",
    "        entity_type = item['entity'][2:]  # Remove the B- or I- prefix\n",
    "        if item['entity'].startswith('B-'):\n",
    "            if current_entity:  # Save the previous entity-value pair if exists\n",
    "                slots.append(f\"{current_entity}={current_value}\")\n",
    "            current_entity = entity_type\n",
    "            current_value = item['word']\n",
    "        elif item['entity'].startswith('I-') and current_entity == entity_type:\n",
    "            current_value += item['word']  # Concatenate words for the same entity\n",
    "\n",
    "    # Append the last entity-value pair\n",
    "    if current_entity:\n",
    "        slots.append(f\"{current_entity}={current_value}\")\n",
    "    \n",
    "            \n",
    "    return slots"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['restaurant-area=west', 'restaurant-food=british']"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predict(\"i am looking for information in cambridge. i am staying in the west and i want to find a place near here that serves real british food .\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['train-departure=cambridge', 'train-leaveat=15:45']"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predict(\"i need to catch a train out of cambridge after 15:45 .\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total number of parameters: 66411327\n"
     ]
    }
   ],
   "source": [
    "total_params = sum(p.numel() for p in model.parameters())\n",
    "print(f\"Total number of parameters: {total_params}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ml",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.15"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
